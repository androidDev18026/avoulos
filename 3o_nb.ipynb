{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d9eab0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [member_name: string, sitting_date: string ... 1 more field]\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", true)\n",
    "            .csv(\"/home/panos/Downloads/Greek_Parliament_Proceedings_1989_2020_DataSample.csv\")\n",
    "            .select(\"member_name\", \"sitting_date\", \"speech\")\n",
    "            .na\n",
    "            .drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "303fb812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- member_name: string (nullable = true)\n",
      " |-- sitting_date: string (nullable = true)\n",
      " |-- speech: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97dfcf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{to_date, to_timestamp}\n",
       "df_date: org.apache.spark.sql.DataFrame = [member_name: string, speech: string ... 1 more field]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// keep rows of a specific year\n",
    "import org.apache.spark.sql.functions.{to_date, to_timestamp}\n",
    "\n",
    "val df_date = df.withColumn(\"date_y\", to_date($\"sitting_date\", \"dd/MM/yyyy\")).drop(\"sitting_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc69fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- member_name: string (nullable = true)\n",
      " |-- speech: string (nullable = true)\n",
      " |-- date_y: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_date.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2a6c86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year: Int = 2015\n",
       "speechesDF: org.apache.spark.sql.DataFrame = [member_name: string, speeches: string]\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val year = 2015 // args(0).toInt\n",
    "\n",
    "val speechesDF = df_date.where(s\"year(date_y) == ${year}\").groupBy(\"member_name\")\n",
    "                    .agg(concat_ws(\",\", collect_list(\"speech\")).as(\"speeches\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "972c5ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleanSpeechesDF: org.apache.spark.sql.DataFrame = [member_name: string, speeches: string ... 1 more field]\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cleanSpeechesDF = speechesDF.withColumn(\"speechesClean\", regexp_replace($\"speeches\", \"[\\\\_,\\\\*,\\\\$,\\\\#,\\\\@,\\\\&]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae61370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|        member_name|            speeches|       speechesClean|\n",
      "+-------------------+--------------------+--------------------+\n",
      "|σακοραφα ηλια σοφια| Κλείστε, κύριε σ...| Κλείστε κύριε συ...|\n",
      "+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanSpeechesDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97286dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.RegexTokenizer\n",
       "speechesDF_tok: org.apache.spark.sql.DataFrame = [member_name: string, speeches: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.RegexTokenizer\n",
    "\n",
    "val speechesDF_tok = new RegexTokenizer().setInputCol(\"speechesClean\")\n",
    "                                            .setOutputCol(\"speechesTok\")\n",
    "                                            .setMinTokenLength(4)\n",
    "                                            .setToLowercase(true)\n",
    "                                            .setPattern(\"[\\\\s.,!-~'\\\";*^%$@()&<>/+_ ]\")\n",
    "                                            .transform(cleanSpeechesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04955e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+\n",
      "|        member_name|            speeches|       speechesClean|         speechesTok|\n",
      "+-------------------+--------------------+--------------------+--------------------+\n",
      "|σακοραφα ηλια σοφια| Κλείστε, κύριε σ...| Κλείστε κύριε συ...|[κλείστε, κύριε, ...|\n",
      "+-------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speechesDF_tok.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7e9fe",
   "metadata": {},
   "source": [
    "#### Filter stopwords!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dfc313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stopwords: Set[String] = Set(πολιτική, όλα, κάνουν, οποίο, πριν, στην, μέσω, ελληνική, ελλάδα, λίγο, ίδιο, εδώ, όλους, πως, ζωή, μου, όταν, για, ώστε, πολλές, θέμα, αποτέλεσμα, πάνω, χωρίς, νέα, υπάρχει, απόφαση, τότε, γιατί, αυτή, του, ήδη, περισσότερο, επειδή, άλλο, ίδια, έχει, ακόμα, εάν, χρόνια, δηλαδή, λοιπόν, τώρα, στις, είπε, περιοχή, ώρα, πρώτο, χώρα, ούτε, παρά, είτε, βάση, χώρας, σύστημα, πάντα, απο, σου, τον, στον, ένα, την, τόσο, όλο, καθώς, πολλά, μεγάλο, γίνει, πώς, φορές, κάτω, οποία, μεταξύ, είχε, γίνεται, σχέση, σχετικά, της, ενός, όχι, όπως, έχουμε, έτσι, εις, δύο, εκεί, κάποια, περίπου, γεγονός, κόσμο, κάθε, αφορά, εργασίας, πρόκειται, χρήση, τέλος, δεν, έχω, μόνο, επίσης, ένας, ενώ, πολύ, έγινε, όσο, κάτι, κάνει, ναι, τελευταία, είχαν, μετά, λόγω, μία, μέσα, τρόπο, α..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stopwords : Set[String] = sc.textFile(\"stopwords.txt\").collect.toSet[String]\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "val filter_stopwords_udf = udf ( (v : scala.collection.mutable.WrappedArray[String]) => v.filterNot(w => stopwords contains w) )\n",
    "\n",
    "val speechesFilteredDF = speechesDF_tok.withColumn(\"speechesTok1\", filter_stopwords_udf(speechesDF_tok(\"speechesTok\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d68bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        member_name|            speeches|       speechesClean|         speechesTok|        speechesTok1|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|σακοραφα ηλια σοφια| Κλείστε, κύριε σ...| Κλείστε κύριε συ...|[κλείστε, κύριε, ...|[κλείστε, κύριε, ...|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speechesFilteredDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95f2e711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.{CountVectorizerModel, CountVectorizer}\n",
       "cvModel: org.apache.spark.ml.feature.CountVectorizerModel = cntVec_64888e5900be\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{CountVectorizerModel, CountVectorizer}\n",
    "\n",
    "val cvModel : CountVectorizerModel = new CountVectorizer().setInputCol(\"speechesTok1\")\n",
    "                                        .setOutputCol(\"features\")\n",
    "                                        .setMinTF(2)\n",
    "                                        .setMaxDF(10) \n",
    "                                        .setVocabSize(10)\n",
    "                                        .fit(speechesFilteredDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76a4451b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cvDF: org.apache.spark.sql.DataFrame = [member_name: string, speechesTok1: array<string> ... 1 more field]\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cvDF = cvModel.transform(speechesFilteredDF).drop(\"speeches\", \"speechesClean\", \"speechesTok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "569dd73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|        member_name|        speechesTok1|            features|\n",
      "+-------------------+--------------------+--------------------+\n",
      "|σακοραφα ηλια σοφια|[κλείστε, κύριε, ...|(10,[0,1,2,3,4],[...|\n",
      "+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7f8732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.rdd.RDD\n",
       "n_most_freq: Int = 5\n",
       "zippedVoc: Array[(String, Int)] = Array((κύριε,0), (συνάδελφε,1), (ευχαριστώ,2), (λόγο,3), (δημοκρατία,4), (αμέσως,5), (κλείστε,6), (κοινοβουλευτικός,7), (εκπρόσωπος,8), (συριζα,9))\n",
       "mostFreq_rdd: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[280] at map at <console>:83\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.linalg.Vector \n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "val n_most_freq = 5\n",
    "\n",
    "val zippedVoc = cvModel.vocabulary.zipWithIndex\n",
    "\n",
    "val mostFreq_rdd : RDD[Array[String]]  = cvDF.select(\"features\")\n",
    "                .rdd\n",
    "                .map(_.getAs[Vector](0))\n",
    "                .map(_.toSparse)\n",
    "                .map{ row => \n",
    "                        row.indices.zip(row.values)\n",
    "                            .sortBy(_._2).take(n_most_freq).map(_._1) }\n",
    "                .map(arr => {\n",
    "                        \n",
    "                        zippedVoc.map { case (word, idx) => \n",
    "                            if (arr.contains(idx)) \n",
    "                                word.toString\n",
    "                        }\n",
    "                    }\n",
    "                .filter(_.!=()))\n",
    "                .map(arr => arr.map(_.toString))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95598966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res46: Array[Array[String]] = Array(Array(κύριε, συνάδελφε, ευχαριστώ, λόγο, δημοκρατία))\n"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostFreq_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "646e56d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\n",
       "members: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [name: string, id: int]\n"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window \n",
    "\n",
    "val members = speechesDF.select(\"member_name\").rdd.map(w => w.toString.replaceAll(\"[\\\\[\\\\]]\",\"\").capitalize).toDF(\"name\").withColumn(\"id\", row_number().over(Window.orderBy(\"name\"))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "272ec3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  Most_Frequent_2015|\n",
      "+--------------------+\n",
      "|[κύριε, συνάδελφε...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Most_Frequent_2015: array<string>]\n"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = mostFreq_rdd.toDF(s\"Most_Frequent_${year}\")\n",
    "\n",
    "df2.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5170817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|  Most_Frequent_2015| id|\n",
      "+--------------------+---+\n",
      "|[κύριε, συνάδελφε...|  1|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mostFreqDF: org.apache.spark.sql.DataFrame = [Most_Frequent_2015: array<string>, id: int]\n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mostFreqDF = df2.withColumn(\"id\", row_number().over(Window.orderBy(s\"Most_Frequent_${year}\")))\n",
    "\n",
    "mostFreqDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e723a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+\n",
      "|               name| id|\n",
      "+-------------------+---+\n",
      "|Σακοραφα ηλια σοφια|  1|\n",
      "+-------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "members.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8fbeea4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------------------------------+\n",
      "|name               |Most_Frequent_2015                             |\n",
      "+-------------------+-----------------------------------------------+\n",
      "|Σακοραφα ηλια σοφια|[κύριε, συνάδελφε, ευχαριστώ, λόγο, δημοκρατία]|\n",
      "+-------------------+-----------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "finalDF: org.apache.spark.sql.DataFrame = [name: string, Most_Frequent_2015: array<string>]\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val finalDF = members.join(mostFreqDF, \"id\").drop(\"id\")\n",
    "\n",
    "finalDF.show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7be90e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.collection.mutable.WrappedArray\n"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.WrappedArray\n",
    "\n",
    "\n",
    "finalDF.rdd.\n",
    "        map { r : org.apache.spark.sql.Row => \n",
    "            (r.getAs[String](0), s\"(${year},(\" + (\n",
    "                r.getAs[WrappedArray[String]](1).mkString(\",\").toString) + \")\")\n",
    "                }.saveAsTextFile(s\"results_${year}\")\n",
    "\n",
    "\n",
    "/*\n",
    "\n",
    "finalDF.rdd.\n",
    "    map { r : org.apache.spark.sql.Row => \n",
    "        ((r.getAs[String](0), Array((year : Int, Array( \n",
    "            r.getAs[WrappedArray[String]](1).toArray.mkString(\",\"))))))}.take(1)//.saveAsTextFile(\"test3\")\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a4351d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: Array[String] = Array(Array[2015)\n"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val x = sc.textFile(\"results_2015/part-00000\").map(x => x.split(\",\")).map(x => x(1)).collect\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e80da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
